{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from src.conf import LAYERS_DIMS, MODEL_FEATURES\n",
    "from src.utils import get_device\n",
    "from src.models import FraudAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_, k_ = 1_000, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=np.random.uniform(** {\"low\": -1, \"high\": 1, \"size\": [n_, k_]}),\n",
    "    columns=[f\"X_{str(i).zfill(3)}\" for i in range(1, 1+k_)]\n",
    ").to_parquet(\"./data/simulated_raw_data_new_arrival.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_001</th>\n",
       "      <th>X_002</th>\n",
       "      <th>X_003</th>\n",
       "      <th>X_004</th>\n",
       "      <th>X_005</th>\n",
       "      <th>X_006</th>\n",
       "      <th>X_007</th>\n",
       "      <th>X_008</th>\n",
       "      <th>X_009</th>\n",
       "      <th>X_010</th>\n",
       "      <th>...</th>\n",
       "      <th>X_291</th>\n",
       "      <th>X_292</th>\n",
       "      <th>X_293</th>\n",
       "      <th>X_294</th>\n",
       "      <th>X_295</th>\n",
       "      <th>X_296</th>\n",
       "      <th>X_297</th>\n",
       "      <th>X_298</th>\n",
       "      <th>X_299</th>\n",
       "      <th>X_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230085</td>\n",
       "      <td>0.215282</td>\n",
       "      <td>0.737480</td>\n",
       "      <td>-0.029383</td>\n",
       "      <td>0.686564</td>\n",
       "      <td>0.204632</td>\n",
       "      <td>0.242007</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.861594</td>\n",
       "      <td>0.160049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435087</td>\n",
       "      <td>-0.657290</td>\n",
       "      <td>0.702238</td>\n",
       "      <td>-0.957188</td>\n",
       "      <td>-0.251992</td>\n",
       "      <td>-0.406932</td>\n",
       "      <td>-0.532268</td>\n",
       "      <td>-0.400508</td>\n",
       "      <td>-0.078877</td>\n",
       "      <td>0.914417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.746929</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.329585</td>\n",
       "      <td>0.223508</td>\n",
       "      <td>-0.933238</td>\n",
       "      <td>0.470296</td>\n",
       "      <td>-0.392319</td>\n",
       "      <td>-0.207745</td>\n",
       "      <td>-0.839040</td>\n",
       "      <td>0.073136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569445</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>0.318652</td>\n",
       "      <td>0.553808</td>\n",
       "      <td>-0.384745</td>\n",
       "      <td>-0.543778</td>\n",
       "      <td>-0.385875</td>\n",
       "      <td>-0.695250</td>\n",
       "      <td>0.552621</td>\n",
       "      <td>-0.878643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.456121</td>\n",
       "      <td>-0.550659</td>\n",
       "      <td>-0.412170</td>\n",
       "      <td>-0.397030</td>\n",
       "      <td>-0.682750</td>\n",
       "      <td>-0.021660</td>\n",
       "      <td>0.358546</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.822910</td>\n",
       "      <td>0.175702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135015</td>\n",
       "      <td>0.868221</td>\n",
       "      <td>0.585312</td>\n",
       "      <td>-0.579202</td>\n",
       "      <td>0.131063</td>\n",
       "      <td>-0.419334</td>\n",
       "      <td>-0.781088</td>\n",
       "      <td>-0.515235</td>\n",
       "      <td>0.451785</td>\n",
       "      <td>0.428911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.207372</td>\n",
       "      <td>-0.111627</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>0.218333</td>\n",
       "      <td>0.964496</td>\n",
       "      <td>-0.429259</td>\n",
       "      <td>-0.638620</td>\n",
       "      <td>0.791188</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>0.997451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185388</td>\n",
       "      <td>-0.912298</td>\n",
       "      <td>0.716268</td>\n",
       "      <td>0.658407</td>\n",
       "      <td>0.778551</td>\n",
       "      <td>-0.910275</td>\n",
       "      <td>-0.086561</td>\n",
       "      <td>0.509355</td>\n",
       "      <td>0.680457</td>\n",
       "      <td>0.476367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126396</td>\n",
       "      <td>-0.172714</td>\n",
       "      <td>-0.174762</td>\n",
       "      <td>0.824663</td>\n",
       "      <td>-0.500215</td>\n",
       "      <td>-0.216015</td>\n",
       "      <td>-0.832705</td>\n",
       "      <td>0.997041</td>\n",
       "      <td>-0.075975</td>\n",
       "      <td>-0.521672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170127</td>\n",
       "      <td>0.248603</td>\n",
       "      <td>-0.047432</td>\n",
       "      <td>-0.487492</td>\n",
       "      <td>-0.897178</td>\n",
       "      <td>-0.627577</td>\n",
       "      <td>-0.774171</td>\n",
       "      <td>-0.207906</td>\n",
       "      <td>0.819025</td>\n",
       "      <td>-0.026374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.357600</td>\n",
       "      <td>0.887004</td>\n",
       "      <td>-0.485512</td>\n",
       "      <td>0.492853</td>\n",
       "      <td>-0.199034</td>\n",
       "      <td>-0.381747</td>\n",
       "      <td>-0.421489</td>\n",
       "      <td>-0.915021</td>\n",
       "      <td>-0.259465</td>\n",
       "      <td>0.116452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515072</td>\n",
       "      <td>0.121284</td>\n",
       "      <td>-0.826953</td>\n",
       "      <td>-0.478490</td>\n",
       "      <td>0.764222</td>\n",
       "      <td>-0.092056</td>\n",
       "      <td>0.810230</td>\n",
       "      <td>0.126713</td>\n",
       "      <td>-0.291540</td>\n",
       "      <td>0.071808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.273161</td>\n",
       "      <td>-0.121791</td>\n",
       "      <td>-0.705445</td>\n",
       "      <td>-0.959673</td>\n",
       "      <td>-0.112367</td>\n",
       "      <td>0.989670</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.550427</td>\n",
       "      <td>-0.329168</td>\n",
       "      <td>0.279856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950121</td>\n",
       "      <td>0.659461</td>\n",
       "      <td>0.203389</td>\n",
       "      <td>-0.304165</td>\n",
       "      <td>-0.777573</td>\n",
       "      <td>0.311494</td>\n",
       "      <td>0.227090</td>\n",
       "      <td>-0.942610</td>\n",
       "      <td>0.520086</td>\n",
       "      <td>-0.420401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.547391</td>\n",
       "      <td>-0.506801</td>\n",
       "      <td>0.363367</td>\n",
       "      <td>0.620437</td>\n",
       "      <td>-0.204963</td>\n",
       "      <td>0.304655</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>-0.894236</td>\n",
       "      <td>0.884614</td>\n",
       "      <td>0.808719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221628</td>\n",
       "      <td>-0.897978</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.835389</td>\n",
       "      <td>-0.406467</td>\n",
       "      <td>0.534537</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.045031</td>\n",
       "      <td>-0.551671</td>\n",
       "      <td>-0.445643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.181385</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>-0.105072</td>\n",
       "      <td>-0.968100</td>\n",
       "      <td>0.863401</td>\n",
       "      <td>-0.364973</td>\n",
       "      <td>0.983601</td>\n",
       "      <td>0.838131</td>\n",
       "      <td>0.791857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.935953</td>\n",
       "      <td>-0.401690</td>\n",
       "      <td>-0.636834</td>\n",
       "      <td>0.071452</td>\n",
       "      <td>0.185493</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>-0.702995</td>\n",
       "      <td>-0.873283</td>\n",
       "      <td>0.541838</td>\n",
       "      <td>-0.347121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.623820</td>\n",
       "      <td>-0.146862</td>\n",
       "      <td>-0.241746</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>-0.386237</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-0.023472</td>\n",
       "      <td>-0.067478</td>\n",
       "      <td>0.437006</td>\n",
       "      <td>-0.950259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092152</td>\n",
       "      <td>-0.847807</td>\n",
       "      <td>-0.723420</td>\n",
       "      <td>-0.890678</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.944262</td>\n",
       "      <td>0.699530</td>\n",
       "      <td>0.500164</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.225789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X_001     X_002     X_003     X_004     X_005     X_006     X_007  \\\n",
       "0    0.230085  0.215282  0.737480 -0.029383  0.686564  0.204632  0.242007   \n",
       "1   -0.746929  0.501888  0.329585  0.223508 -0.933238  0.470296 -0.392319   \n",
       "2   -0.456121 -0.550659 -0.412170 -0.397030 -0.682750 -0.021660  0.358546   \n",
       "3    0.207372 -0.111627  0.993033  0.218333  0.964496 -0.429259 -0.638620   \n",
       "4    0.126396 -0.172714 -0.174762  0.824663 -0.500215 -0.216015 -0.832705   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995 -0.357600  0.887004 -0.485512  0.492853 -0.199034 -0.381747 -0.421489   \n",
       "996 -0.273161 -0.121791 -0.705445 -0.959673 -0.112367  0.989670  0.015037   \n",
       "997 -0.547391 -0.506801  0.363367  0.620437 -0.204963  0.304655  0.112276   \n",
       "998  0.181385  0.984729  0.067592 -0.105072 -0.968100  0.863401 -0.364973   \n",
       "999  0.623820 -0.146862 -0.241746  0.024943 -0.386237  0.460810 -0.023472   \n",
       "\n",
       "        X_008     X_009     X_010  ...     X_291     X_292     X_293  \\\n",
       "0    0.763501  0.861594  0.160049  ... -0.435087 -0.657290  0.702238   \n",
       "1   -0.207745 -0.839040  0.073136  ...  0.569445  0.605132  0.318652   \n",
       "2    0.343715  0.822910  0.175702  ... -0.135015  0.868221  0.585312   \n",
       "3    0.791188  0.493548  0.997451  ... -0.185388 -0.912298  0.716268   \n",
       "4    0.997041 -0.075975 -0.521672  ...  0.170127  0.248603 -0.047432   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995 -0.915021 -0.259465  0.116452  ... -0.515072  0.121284 -0.826953   \n",
       "996  0.550427 -0.329168  0.279856  ... -0.950121  0.659461  0.203389   \n",
       "997 -0.894236  0.884614  0.808719  ... -0.221628 -0.897978  0.085584   \n",
       "998  0.983601  0.838131  0.791857  ... -0.935953 -0.401690 -0.636834   \n",
       "999 -0.067478  0.437006 -0.950259  ... -0.092152 -0.847807 -0.723420   \n",
       "\n",
       "        X_294     X_295     X_296     X_297     X_298     X_299     X_300  \n",
       "0   -0.957188 -0.251992 -0.406932 -0.532268 -0.400508 -0.078877  0.914417  \n",
       "1    0.553808 -0.384745 -0.543778 -0.385875 -0.695250  0.552621 -0.878643  \n",
       "2   -0.579202  0.131063 -0.419334 -0.781088 -0.515235  0.451785  0.428911  \n",
       "3    0.658407  0.778551 -0.910275 -0.086561  0.509355  0.680457  0.476367  \n",
       "4   -0.487492 -0.897178 -0.627577 -0.774171 -0.207906  0.819025 -0.026374  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.478490  0.764222 -0.092056  0.810230  0.126713 -0.291540  0.071808  \n",
       "996 -0.304165 -0.777573  0.311494  0.227090 -0.942610  0.520086 -0.420401  \n",
       "997  0.835389 -0.406467  0.534537  0.502468  0.045031 -0.551671 -0.445643  \n",
       "998  0.071452  0.185493  0.035622 -0.702995 -0.873283  0.541838 -0.347121  \n",
       "999 -0.890678  0.065832  0.944262  0.699530  0.500164  0.067216  0.225789  \n",
       "\n",
       "[1000 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"/home/onyxia/work/fraud_detection/data/simulated_raw_data_new_arrival.gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_device(1)\n",
    "\n",
    "_LAYERS_DIMS = LAYERS_DIMS(\n",
    "    INPUT_DIM=300,\n",
    "    HIDDEN_DIM=150,\n",
    "    CODE_DIM=35\n",
    ")\n",
    "model = FraudAutoEncoder(_LAYERS_DIMS).to(DEVICE)\n",
    "model_hyperparams = MODEL_FEATURES(\n",
    "    LEARNING_RATE=1e-3,\n",
    "    N_EPOCHS=100\n",
    ")\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=model_hyperparams.LEARNING_RATE\n",
    ")\n",
    "loss_criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudAutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=150, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=150, out_features=35, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=35, out_features=150, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=150, out_features=300, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"./models/best_model_simulated_data.ckpt\", map_location=\"cuda\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
